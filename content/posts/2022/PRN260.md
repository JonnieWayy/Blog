---
title: "[论文阅读笔记 -- ReID] Learning Granularity-Unified Representations for T2I ReID (MM 2022)"
date: 2022-08-19T16:31:48+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Learning Granularity-Unified Representations for Text-to-Image Person Re-identification (MM 2022)

[开源代码传送门](https://github.com/ZhiyinShao-H/LGUR)

![Fig 1](/images/2022/PRN260/1.png)

## 概述

视觉特征包含细粒度信息，而文本特征描述粗粒度属性，这导致了同一句文本描述适用于相似而不相同的多张图像。  

本文提出一种学习粒度统一表征的架构 (Learning Granularity-Unified Representations, LGUR@sl)，将图文特征映射到一个粒度统一的特征空间中，其包含一个基于字典的粒度对齐模块 (Dictionary-based Granularity Alignment module, DGA) 和一个基于原型的粒度统一模块 (Prototype-based Granularity Unification module, PGU)。  

![Fig 2](/images/2022/PRN260/2.png)

## Dictionary-based Granularity Alignment

本文认为将图像特征进一步抽象化能使得图文特征匹配得更为紧密。  

用 transformer 中的交叉注意力操作进行重构过程：  

$$T_{re} = MHA_{1}(T, D, D).$$

视觉特征的重构引入了一个前景掩码：  

$$V_{re} = MHA_{1}(V, D, D) \odot M.$$

此外利用文本特征得到更抽象的视觉特征：  

$$V_{g} = MHA_{1}(V, T, T) \odot M.$$

## Prototype-based Granularity Unification

旨在将图文特征有映射到同一个特征空间中。  

## 可视化示例

![Fig 3](/images/2022/PRN260/3.png)

![Fig 4](/images/2022/PRN260/4.png)
