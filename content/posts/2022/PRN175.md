---
title: "[论文阅读笔记 -- ReID] Explainable ReID With Attribute-Guided Metric Distillation (ICCV 2021)"
date: 2022-01-21T14:49:33+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Explainable Person Re-Identification With Attribute-Guided Metric Distillation (ICCV 2021)

[开源代码传送门](https://github.com/SheldongChen/AMD.github.io)

![Fig 1](/images/2022/PRN175/1.png)

## 概述

旨在借助语义属性学习一个解释器，以回答如下两个问题：  
+ 是什么属性使两个人不同？
+ 各属性对差异有多大的影响？  

本文提出一种事后方法 (post-hoc method)，称为 Attribute-guided Metric Distillation (AMD)。  

![Fig 2](/images/2022/PRN175/2.png)

## 本文方法

### Attribute-guided Metric Interpreter

在训练解释器时固定目标 ReID 模型参数。  

解释器网络前几层与 ReID 模型共享，后续层可学习。  

利用属性分解头 (Attribute Decomposition Head, ADH) 得到属性指导的注意力图 (AAMs)，沿着通道维分割属于不同属性。

用 Positive Exponential Power Unit (PePU) 替代 Sigmoid：  

$$\sigma(x) = \begin{cases}\kappa \cdot (x + 1)^{\tau}, \quad x \gt 0,\\\\ \kappa \cdot e^x, \quad x \le 0.\end{cases}$$

### 损失函数 

Metric Distillation Loss + Attribute Prior Loss

## 可视化示例

![Fig 4](/images/2022/PRN175/4.png)
