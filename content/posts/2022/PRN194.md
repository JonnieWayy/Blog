---
title: "[论文阅读笔记 -- ReID] Robust Person ReID by Modelling Feature Uncertainty (ICCV 2019)"
date: 2022-02-21T12:55:36+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID", "uncertainty"]
draft: false
---

# Robust Person Re-identification by Modelling Feature Uncertainty (ICCV 2019)

[开源代码传送门](https://github.com/TianyuanYu/DistributionNet)

![Fig 1](/images/2022/PRN194/1.png)

![Fig 2](/images/2022/PRN194/2.png)

## 概述

本文关注如何用带噪训练数据学习一个健壮的 ReID 模型，数据噪声可以分为两类：  
+ Label Noise
+ Data Outliers

本文提出 DistributionNet 以应对这两种噪声样本，各张图像被表征为一个特征分布 (高斯分布) 而非特征向量，其均值的作用类似于特征向量，而方差则衡量特征的不确定性，不确定性高的样本对特征嵌入空间的学习影响较小。  

![Fig 3](/images/2022/PRN194/3.png)

## 模型架构

### 分类损失

ID Loss 的输入为均值向量 \\(\mu\\) 和 \\(N\\) 个从相应高斯分布随机采样得到的样本，后者的损失求均值后权重设为 \\(0.1\\)。  

随着该损失的训练，方差会持续下降，导致模型逐渐趋近于传统模型，因而需要另一个损失来维持方差。  

### 特征不确定性损失

首先用熵衡量训练样本的不确定性：  

$$q = \frac{1}{2}log(det(2\pi e\Sigma)) = \frac{m}{2}(log 2\pi + 1) + \frac{1}{2} \sum_{k}^{m} log(diag(\Sigma^{(i)})\_{k}).$$

$$L_{fu} = max(0, \gamma - \sum_{i=1}^n q^{(i)}),$$

其中 \\(\gamma\\) 是边界值。  
