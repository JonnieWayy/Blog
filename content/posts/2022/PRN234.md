---
title: "[论文阅读笔记 -- ReID] Learning Memory-Augmented Unidirectional Metrics for ReID (CVPR 2022)"
date: 2022-06-13T15:57:14+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Learning Memory-Augmented Unidirectional Metrics for Cross-modality Person Re-identification (CVPR 2022)

![Fig 1](/images/2022/PRN234/1.png)

## 概述

本文提出一种 Memory-Augmented Unidirectional Metric (MAUM) 学习方法。

其学习两个单向的尺度，即 IR to RGB 和 RGB to IR，而非通常的一个公共中转，得到两个模态特定的代理 (Modality-Specific Proxies, MS-Proxies)，固定后用于指引对面模态。   

此外，通过 memory bank 进一步增强学到的单向代理。  

与现有工作认为 drift 现象有负面影响并设法避免相反，本文利用 drift 现象来提升表现。  

本文方法在模态不平衡的场景下有其特定的优势。  

### 模型架构

![Fig 2](/images/2022/PRN234/2.png)

### Proxy Drift

![Fig 3](/images/2022/PRN234/3.png)

![Fig 4](/images/2022/PRN234/4.png)
