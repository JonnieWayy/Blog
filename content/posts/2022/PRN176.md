---
title: "[论文阅读笔记 -- 知识蒸馏] SimReg: Regression as a Simple Yet Effective Tool (BMVC 2021)"
date: 2022-01-23T14:22:49+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "knowledge distillation", "regression", "self-supervised"]
draft: false
---

# 2201.05131 SimReg: Regression as a Simple Yet Effective Tool for Self-supervised Knowledge Distillation (BMVC 2021)

[开源代码传送门](https://github.com/UCDvision/simreg)

![Fig 1](/images/2022/PRN176/1.png)

## 概述

本文关注自监督模型的蒸馏，发现 backbone 输出的特征比预测头最后一层输出的特征能更好地与教师模型相匹配。  

监督与自监督的知识蒸馏一大区别在于前者在学生模型学生模型训练时除了蒸馏损失还有一个借助标签的监督损失。  
