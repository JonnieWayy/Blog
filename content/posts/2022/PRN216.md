---
title: "[论文阅读笔记 -- 增量学习] Co2L: Contrastive Continual Learning (ICCV 2021)"
date: 2022-03-22T20:05:02+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "lifelong"]
draft: true
---

# Co2L: Contrastive Continual Learning (ICCV 2021)

[开源代码传送门](https://github.com/chaht01/Co2L)

![Fig 1](/images/2022/PRN216/1.png)

## 概述

### 现有方法归类

+ Replay-based Approaches
+ Regularization-based Approaches
+ Expansion-based Approaches

### 本文关注的基本问题

什么类型的知识对未来任务有用并因此不会被忘记？  

应该怎样学习和保留这样的知识？  

### 想法

遗忘不仅来自于对过往经验的有限访问，也来自于对未来事件的受限访问。因此为了防止遗忘，学习一手的更加可迁移的表征与小心保留过往获得的知识同样重要。  

本文发现对比学习得到的表征比交叉熵损失训练得到的更不易受遗忘的影响。  

### 将该想法应用于增量学习的两个困难

+ 对比学习需要获取好的负样本，而标准增量步下可获取的负样本有限
+ 如何在增量学习设定下保留对比学习得到的表征，这一问题尚未得到很好的回答

本文提出一种新的基于 rehearsal 的增量学习算法，称为对比增量学习 (Contrastive Continual Learning, Co\\(^2\\)L)。  

### 本文考虑三种增量学习场景

+ Task-incremental Learning (Task-IL)
+ Class-incremental Learning (Class-IL)
+ Domain-incremental Learning (Domain-IL)

前两者的任务特定类别集合互补重合，而后者保持一致；前者测试时可以看到任务标签，而后两者测试时不能。  

![Fig 2](/images/2022/PRN216/2.png)

## 本文方法

### Representation Learning with Asymmetric Supervised Contrastive Loss

以当前任务样本作为 anchor，而过去任务的样本只用做负样本。  

### Instance-wise Relation Distillation (IRD) for Contrastive Continual Learning

利用自蒸馏对 batch 样本之间特征关系的变换进行正则化。  
