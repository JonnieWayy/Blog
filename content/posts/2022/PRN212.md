---
title: "[论文阅读笔记 -- ReID] Part-Aware Self-Supervised Pre-Training for Person ReID (2022)"
date: 2022-03-16T08:16:08+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID", "ViT"]
draft: false
---

# 2203.03931 Part-Aware Self-Supervised Pre-Training for Person Re-identification (2022)

[开源代码传送门](https://github.com/CASIA-IVA-Lab/PASS-reID)

![Fig 1](/images/2022/PRN212/1.png)

## 概述

研究表明在 LUPerson 上无监督预训练的表现比 ImageNet 上监督预训练更好。先前的工作直接采用现有的分类任务上的 SSL 方法，并不能完美适应 ReID 任务。  

本文提出一种专门针对 ReID 的预训练方法，称为 Part-Aware Self-Supervised Pre-training (PASS)，自动提取局部特征。  

### 模型架构

![Fig 2](/images/2022/PRN212/2.png)

基于自监督方法 DINO，教师模型由过往迭代的学生模型构建得到，更新规则为：  
$$\theta_{t} \leftarrow \lambda \theta_{t} + (1 - \lambda) \theta_{s},$$
其中 \\(\lambda\\) 遵循 cosine schedule 从 0.996 到 1 变化。  

构建 global view 和 local view，教师模型仅以前者为输入，学生模型以二者为输入。对于前者，[CLS] 和所有 [PART] 拼接到相应的 patch 嵌入；而对于后者，只有 [CLS] 和对应 [PART] 拼接。  

微调时用教师模型，直接将 [CLS] 和所有 [PART] 和输入图像的 patch 序列拼接即可。  

### 可视化示例

![Fig 3](/images/2022/PRN212/3.png)

![Fig 4](/images/2022/PRN212/4.png)
