---
title: "[论文阅读笔记 -- 跨模态检索] Adaptive CM Prototypes for Cross-Domain VLR (CVPR 2021)"
date: 2022-02-16T22:09:12+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "cross-domain"]
draft: false
---

# Adaptive Cross-Modal Prototypes for Cross-Domain Visual-Language Retrieval (CVPR 2021)

![Fig 1](/images/2022/PRN191/1.png)

## 概述

将在带标签源域上学习到的模型迁移到不带标签的目标域的任务被称为无监督域自适应 (UDA)，本文研究 UDA 设定下的跨模态检索问题，主要面临三大挑战：  
+ Compositionality: 模型需要对多种视觉目标的组合形式进行语义编码
+ Reporting Bias: 文本通常不会描述到图中所有的细节
+ Visual And Text Domain Shifts: 不同域中的图像与文本数据都可能存在较大的差异

本文提出一种自适应跨模态原型架构 (Adaptive Cross-modal Prototypes framework, ACP)。  

### 本文方法

![Fig 2](/images/2022/PRN191/2.png)

### 特征可视化

![Fig 3](/images/2022/PRN191/3.png)
