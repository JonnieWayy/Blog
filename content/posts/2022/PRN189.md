---
title: "[论文阅读笔记 -- ReID] Object ReID Using Teacher-Like and Light Students (BMVC 2021)"
date: 2022-02-15T13:35:16+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID", "knowledge distillation"]
draft: false
---

# Object Re-identification Using Teacher-Like and Light Students (BMVC 2021)

![Fig 1](/images/2022/PRN189/1.png)

## 概述

本文提出一种联合蒸馏与剪枝方法 (Joint Distillation and Pruning method, JDP) 以学习与教师相似且轻量的学生模型 (Teacher-Like and Light students, TTL students)，其结合了知识蒸馏、模型剪枝和结构再参数化三种技术。  

### The Pruner-Convolution-Pruner Block Using Group LASSO

构建 PCP 块，包含 \\(1 \times 1\\) 卷积、带 bias 的 \\(K \times K\\) 卷积和 \\(1 \times 1\\) 卷积，用于替代学生模型中的 \\(K \times K\\) 卷积，其剪枝器初始化为单位矩阵。  

PCP 块中 \\(K \times K\\) 卷积的通道数由其剪枝器控制，在学生模型训练时，用 group LASSO 使 PCP 块的剪枝器稀疏化，从而间接对 \\(K \times K\\) 卷积层进行剪枝。  

### Joint Knowledge Distillation and Pruning

为了避免无约束剪枝，引入知识蒸馏，对 logit 值计算 KL 散度，对隐层计算欧几里德距离。  

此外还用到交叉熵损失和三元组损失。  
