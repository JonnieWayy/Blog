---
title: "[论文阅读笔记 -- 特征分解] Visual Concepts Tokenization (NeurIPS 2022)"
date: 2022-10-23T16:27:03+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "tokenization"]
draft: false
---

# Visual Concepts Tokenization (NeurIPS 2022)

[开源代码传送门](https://github.com/thomasmry/VCT)

## 概述

本文针对视觉概念学习 (visual concept learning)，提出一种基于 transformer 的无监督方法，称为视觉概念令牌化 (Visual Concept Tokenization, VCT)，其包含一个 Concept Tokenizer 和一个 Concept Detokenizer。  

分解得到的令牌应该符合以下条件：  

+ 完备性 (completeness)，可以通过这些令牌重构图像
+ 解构性 (disentanglement)，不同令牌应当表征独立的视觉概念，且各令牌应只反映一种视觉概念变量
+ 无序性 (disorder)，令牌的排列顺序应当不传递任何信息

本文将符合上述条件的令牌称为概念令牌 (concept tokens)。  

### VCT 模型架构

![Fig 1](/images/2022/PRN289/1.png)

Tokenizer 中，对图像令牌采用带自注意力的标准 transformer 层处理，对概念部分采用不带后续自注意力交叉注意力 \\((Q, K, V)\\) 处理。其中，自注意力中的 Q 来自概念部分，K 和 V 来自图像部分，各交叉注意力块后跟随一个 FFN。概念令牌相互之间没有交互，保证各自信息独立。  

Detokenizer 中，设计了一个图像 query 阵列 Y，用于查询概念令牌中包含的视觉信息。将 Y 用作 Q，概念令牌用作 K 和 V。为了混合孤立的视觉信息，在交叉注意力后加上自注意力运算。  

### Concept Disentangling Loss

![Fig 2](/images/2022/PRN289/2.png)

旨在确保概念令牌之间的互斥性。其包含两个步骤：  

+ 通过替换一个概念令牌，产生图像差异
+ 识别该图像差异

差异计算如下：  

$$\Delta C = \mathcal{V}\_{T}(\mathcal{I}\_{T}(x'\_{i})) - \mathcal{V}\_{T}(\mathcal{I}\_{T}(\hat{x}'\_{i})).$$

概念解构损失为：  

$$\mathcal{L}\_{dis} = CrossEntropy(norm(\Delta C), l).$$

### 可视化示例

![Fig 3](/images/2022/PRN289/3.png)

![Fig 4](/images/2022/PRN289/4.png)

![Fig 5](/images/2022/PRN289/5.png)

![Fig 6](/images/2022/PRN289/6.png)
