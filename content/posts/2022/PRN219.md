---
title: "[论文阅读笔记 -- ReID] Uncertainty-Aware Multi-Shot Knowledge Distillation for ReID (AAAI 2020)"
date: 2022-04-07T17:39:01+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID", "uncertainty"]
draft: false
---

# Uncertainty-Aware Multi-Shot Knowledge Distillation for Image-Based Object Re-Identification (AAAI 2020)

![Fig 1](/images/2022/PRN219/1.png)

## 概述

本文提出一种不确定性可知的多设教师-学生网络 (Uncertainty-aware Multi-shot Teacher-Student Network, UMTS)，包含一个教师网络和一个学生网络，利用多张图像来增强表现。  

![Fig 2](/images/2022/PRN219/2.png)

## 本文方法

多张图像能比单张图像提供更多信息，但是推断阶段只有一张图，因此本文考虑知识蒸馏。  

T-Net 和 S-Net 结构相同，只是输入的通道数不同。  

本文设计了一个不确定性可知的知识蒸馏损失：  

$$\mathcal{L}\_{UKD(i, :)}^b = \sum_{k=1}^K \frac{1}{2 \sigma_{b}(y_{i}^b, x_{i, k}^k)^2} ||\theta_{t}^b(y_{i}^b) - \theta_{s}^b(x_{i, k}^b)||^2 + log \sigma_{b}(y_{i}^b, x_{i, k}^b),$$
$$log(\sigma_{b}(y_{i}^b, x_{i, k}^b)^2) = ReLU(W_{b}[\theta_{t}^b(y_{i}^b), \theta_{s}^b(x_{i, k}^b)]).$$

![Fig 3](/images/2022/PRN219/3.png)

## 可视化示例

![Fig 5](/images/2022/PRN219/5.png)
