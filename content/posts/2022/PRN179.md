---
title: "[论文阅读笔记 -- ReID] Divide-and-Merge the Embedding Space (Neurocomputing 2021)"
date: 2022-01-29T14:55:04+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Divide-and-Merge the Embedding Space for Cross-modality Person Search (Neurocomputing 2021)

![Fig 1](/images/2022/PRN179/1.png)

## 概述
本文提出一种分治嵌入学习架构 (Divide-and-Merge Embedding Learning Framework, DME)，关注两方面：  
+ 如何提取健壮的局部表征，而避免产生无意义信息
+ 如何有效合并多样的局部表征，从而得到具有鉴别力的全局嵌入

![Fig 2](/images/2022/PRN179/2.png)

## 本文方法

### Feature Dividing Network (FDN)

将不同的局部特征分组以描述行人的不同部分。  

采用自注意力嵌入，计算 \\(K\\) 个注意力系数，通过线性组合得到相应的表征：  

$$\alpha = softmax(w_{2} tanh(w_{1}f^T(\*))) \in \mathbb{R}^K,$$
$$\phi(\*) = \frac{\alpha f(\*)}{||\alpha f(\*)||} \in \mathbb{R}^{K \times 512}.$$

![Fig 3](/images/2022/PRN179/3.png)

### Relevance Based Subspace Projection

将 \\(K\\) 个表征压缩未一个低维的全局嵌入，比起直接拼接维度更低。遵循 Minimum Redundancy Maximum Relevance (nRMR) 规则优化参数。  

## 检索结果示例

![Fig 11](/images/2022/PRN179/11.png)
