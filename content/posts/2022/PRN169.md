---
title: "[论文阅读笔记 -- 跨模态检索] Integrating Information Theory and Advers. Learning (PR 2021)"
date: 2022-01-13T13:21:37+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval"]
draft: false
---

# Integrating Information Theory and Adversarial Learning for Cross-modal Retrieval (PR 2021)

![Fig 1](/images/2022/PRN169/1.png)

## 概述

本文将香农信息论与对抗学习相结合，以对抗的方式结合信息熵预测器与模态分类器。  

![Fig 2](/images/2022/PRN169/2.png)

## 本文方法

### 信息熵与模态不确定性

用信息熵衡量公共空间的不确定性，当两种模态具有相等几率时会使得香农信息熵最大，从而使得信息量最大。  

### 对抗学习与信息熵

鉴别器进行模态分类，基于跨模态特征识别视觉与文本模态。利用鉴别器所输出的几率可以计算得到交叉熵损失，以实现模态分类，从而最小化模态不确定性。  

相反，生成器旨在最大化模态不确定性。  

![Fig 3](/images/2022/PRN169/3.png)

### 针对跨模态特征投影的 KL 散度

用 KL 散度建模投影后跨模态特征与利用其实例标签计算得到监督矩阵之间的差异，考虑 mini-batch 中所有正负样本对：  

$$KL((f(Z^i, Z^t) || f(Y_{l}^T, Y_{l}))).$$

采用跨模态特征投影实现 \\(f(\cdot)\\) 操作：  

$$\hat{z}^{i \rightarrow t}\_{j} = |z_{j}^i| \* \frac{<z_{j}^i, z_{k}^t>}{|z_{j}^i||z_{k}^{t}|} \* \frac{z_{k}^t}{|z_{k}^t|} = <z_{j}^i, \overline{z}\_{k}^t> \* \overline{z}\_{k}^t.$$

因此该向量的长度就是 \\(|<z_{j}^i, \overline{z}\_{k}^t>|\\)，表示两个特征之间的相似度，从而可以得到两个相似度矩阵：  

$$A_{i \rightarrow t}(Z^i, Z^t) = \sum_{j=1}^N \sum_{k=1}^N |<z_{j}^i, \overline{z}\_{k}^t>| = Z^i(\overline{Z}^t)^T,$$
$$A_{t \rightarrow i}(Z^t, Z^i) = \sum_{k=1}^N \sum_{j=1}^N |<z_{k}^t, \overline{z}\_{j}^i>| = Z^t(\overline{Z}^i)^T.$$
