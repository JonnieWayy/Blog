---
title: "[论文阅读笔记 -- ReID] View Confusion Feature Learning for Person ReID  (ICCV 2019)"
date: 2021-11-26T15:23:07+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# View Confusion Feature Learning for Person Re-identification (ICCV 2019)

![Fig 1](/images/2021/PRN125/1.png)

## 概述

本文提出一种视角混淆特征学习模型 (View Confusion Feature Learning, VCFL)，通过结合 view-generic 与 view-specific 模型学习 view-invariant 的特征。  

从三个层面实现视角混淆：  
+ 基于分类器的混淆
+ 基于特征的混淆
+ 基于 sift 的混淆

![Fig 2](/images/2021/PRN125/2.png)

## 本文方法

### 特征学习

基本架构选用 googlenet 或 resnet，损失函数用三元组损失。  

### 视角信息 (VI)

视角信息分为前、后、左、右四种，采用一个视角分支 (view branch) 进行预测。  

### 基于分类器的混淆

特征提取器 + 视角分类器，采用对抗学习策略。    

后者旨在将特征分类为特定视角，前者旨在学习能被分类器分类为 common 视角的特征。  

损失函数为：  

$$L(\theta_{f}, \theta_{d}) = L_{f}(\theta_{f}) + L_{d}(\theta_{f}, \theta_{d}),$$
$$\hat{\theta}\_{f} = arg \ min\_{\theta\_{f}} \mathcal{L}(\theta_{f}, \hat{\theta}\_{d}),$$
$$\hat{\theta}\_{d} = arg \ min\_{\theta\_{d}} \mathcal{L}(\hat{\theta}\_{f}, \theta_{d}).$$

### 基于特征的混淆

基于 center loss，目的在于使得各个样本同时与视角中心以及整体中心接近：  

$$L_{cen} = \frac{1}{2} \sum_{i=1}^{N} ||h(I_{i}) - h(C_{y_{i}})||\_{2}.$$

### 基于 sift 的混淆

将 sift 特征与深度特征结合。使用 BOW 模型提取 sift-bow 向量，由于 sift 特征是独立于视角的，深度特征与之越接近则说明其越独立于视角。因而损失定义为：  

$$L_{sg} = \sum_{i=1}^{N} ||f(x_{i}) - g(x_{o})||\_{2}.$$

## 特征可视化

![Fig 3](/images/2021/PRN125/3.png)

## 检索结果可视化

![Fig 4](/images/2021/PRN125/4.png)
