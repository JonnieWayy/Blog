---
title: "[论文阅读笔记 -- ReID] Pose-guided Feature Disentangling for Occluded ReID (AAAI 2022)"
date: 2021-12-24T18:43:24+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Pose-guided Feature Disentangling for Occluded Person Re-identification Based on Transformer (AAAI 2022)

[开源代码传送门](https://github.com/WangTaoAs/PFD_Net)

![Fig 1](/images/2021/PRN139/1.png)

## 概述

本文试图在不涉及空间对齐的情况下结合额外的姿态信息与 Transformer，提出一种姿态指导的特征解构 Transformer (Pose-guided Feature Disentangling Transformer, PFD)，其主要包含如下几个模块：  

+ visual context transformer encoder
+ pose estimator
+ Pose-guided Feature Aggregation (PFA) module
+ part view based transformer decoder
+ Pose-View Matching (PVM) module

![Fig 2](/images/2021/PRN139/2.png)

## PFD

### Visual Context Transformer Encoder

基于 ViT 构建，采用 id loss 和 triplet loss。  

### Pose-guided Feature Aggregation

通过一个匹配与分配的机制 (matching and distributing mechanism) 找到 \\(f_{gp}\\) 中对某个身体部件贡献最高的一部分信息。  

### Part View Based Transformer Decoder

定义了一组可学习的语义部件视角 (semantic part view) 以学习具有鉴别力的身体部件。  

## 特征可视化
![Fig 5](/images/2021/PRN139/5.png)
