---
title: "[论文阅读笔记 -- ReID] Learning To Know Where To See for Occluded ReID (ICCV 2021)"
date: 2021-11-29T16:50:29+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Learning To Know Where To See: A Visibility-Aware Approach for Occluded Person Re-Identification (ICCV 2021)

![Fig 1](/images/2021/PRN131/1.png)
![Fig 2](/images/2021/PRN131/2.png)

## 概述

随着姿态估计粒度的细化，其预测误差随之上升。  

本文试图找到一种策略，能在不过分依赖姿态信息的情况下处理遮挡问题，即使用粗粒度的姿态信息得到好的表现。  

首先学习一个局部标签生成器 (part label generator)，为各身体部件生成局部标签。基于生成的标签，学习一个区域可见性鉴别器 (region visibility discriminator)。  

再者，利用预训练好的姿态估计模型，得到姿态信息，包括其坐标与置信度。通过冗余投票 (redundant voting) 利用这些信息，决定一个部分是可见的还是被遮挡的。  

在测试阶段，可以直接使用学习好的区域可视性鉴别器，而无需姿态估计来得到可见性评分。  
