---
title: "炼丹杂记 -- PyTorch 特征傅利叶变换幅度相位分离与重建"
date: 2021-08-16T17:57:11+08:00
categories: ["Alchemy Of CV"]
tags: ["cv", "notes", "deep learning", "pytorch", "fft", "frequency", "numpy", "python"]
draft: false
---

简单记录一下如何使用 PyTorch 对做过傅利叶变换后的特征进行幅度与相位的分离与重建。  

```
In [1]: import torch
In [2]: import numpy as np
# 生成一个张量作为特征
In [3]: feat = torch.rand((3,10))
In [4]: feat
Out[4]:
tensor([[3.7899e-01, 2.9198e-01, 6.4575e-01, 6.6436e-02, 6.5869e-01, 4.8748e-01,
1.9435e-01, 2.4877e-01, 7.8698e-01, 1.3277e-01],
[6.3847e-01, 8.6564e-01, 8.8914e-01, 8.0056e-01, 1.1412e-01, 8.1001e-03,
7.4638e-01, 6.9028e-01, 3.3555e-01, 1.2327e-01],
[6.1691e-05, 5.2777e-01, 9.7296e-01, 6.8016e-01, 9.2669e-01, 9.0223e-01,
6.3513e-01, 4.3459e-01, 1.5316e-02, 2.4932e-01]])
# 傅利叶变换
In [5]: feat_fft = torch.fft.fft(feat)
In [6]: feat_fft
Out[6]:
tensor([[ 3.8922+0.0000j, -0.1096-0.0588j, -0.1528+0.2660j, -0.8802-0.7832j,
0.3729+0.2184j,  1.4373+0.0000j,  0.3729-0.2184j, -0.8802+0.7832j,
-0.1528-0.2660j, -0.1096+0.0588j],
[ 5.2115+0.0000j,  0.6520-0.6961j, -0.9788-1.5679j,  0.8060+0.2855j,
-0.0105-0.3864j,  0.2358+0.0000j, -0.0105+0.3864j,  0.8060-0.2855j,
-0.9788+1.5679j,  0.6520+0.6961j],
[ 5.3442+0.0000j, -1.5761-1.4794j, -0.0763-0.4061j, -0.5573+0.1651j,
-0.3401+0.6849j, -0.2439+0.0000j, -0.3401-0.6849j, -0.5573-0.1651j,
-0.0763+0.4061j, -1.5761+1.4794j]])
# 求模得到幅度谱
In [7]: feat_fft_a = torch.abs(feat_fft)
In [8]: feat_fft_a
Out[8]:
tensor([[3.8922, 0.1244, 0.3068, 1.1782, 0.4321, 1.4373, 0.4321, 1.1782, 0.3068,
0.1244],
[5.2115, 0.9538, 1.8484, 0.8551, 0.3865, 0.2358, 0.3865, 0.8551, 1.8484,
0.9538],
[5.3442, 2.1616, 0.4132, 0.5813, 0.7647, 0.2439, 0.7647, 0.5813, 0.4132,
2.1616]])
# 求相角得到相位谱
In [9]: feat_fft_p = torch.angle(feat_fft)
In [10]: feat_fft_p
Out[10]:
tensor([[ 0.0000, -2.6495,  2.0921, -2.4144,  0.5300,  0.0000, -0.5300,  2.4144,
-2.0921,  2.6495],
[ 0.0000, -0.8181, -2.1289,  0.3404, -1.5979,  0.0000,  1.5979, -0.3404,
2.1289,  0.8181],
[ 0.0000, -2.3878, -1.7566,  2.8536,  2.0316,  3.1416, -2.0316, -2.8536,
1.7566,  2.3878]])
# 由幅度谱和相位谱计算特征，与分解前一致
In [11]: feat_fft_recon = feat_fft_a * np.e ** (1j * feat_fft_p)
In [12]: feat_fft_recon
Out[12]:
tensor([[ 3.8922+0.0000e+00j, -0.1096-5.8784e-02j, -0.1528+2.6603e-01j,
-0.8802-7.8322e-01j,  0.3729+2.1844e-01j,  1.4373+0.0000e+00j,
0.3729-2.1844e-01j, -0.8802+7.8322e-01j, -0.1528-2.6603e-01j,
-0.1096+5.8784e-02j],
[ 5.2115+0.0000e+00j,  0.6520-6.9611e-01j, -0.9788-1.5679e+00j,
0.8060+2.8550e-01j, -0.0105-3.8636e-01j,  0.2358+0.0000e+00j,
-0.0105+3.8636e-01j,  0.8060-2.8550e-01j, -0.9788+1.5679e+00j,
0.6520+6.9611e-01j],
[ 5.3442+0.0000e+00j, -1.5761-1.4794e+00j, -0.0763-4.0608e-01j,
-0.5573+1.6513e-01j, -0.3401+6.8493e-01j, -0.2439+3.6829e-08j,
-0.3401-6.8493e-01j, -0.5573-1.6513e-01j, -0.0763+4.0608e-01j,
-1.5761+1.4794e+00j]])
# 还原为输入特征，二者一致
In [13]: feat_ifft = torch.real(torch.fft.ifft(feat_fft_recon))
In [14]: feat_ifft
Out[14]:
tensor([[3.7899e-01, 2.9198e-01, 6.4575e-01, 6.6436e-02, 6.5869e-01, 4.8748e-01,
1.9435e-01, 2.4877e-01, 7.8698e-01, 1.3277e-01],
[6.3847e-01, 8.6564e-01, 8.8914e-01, 8.0056e-01, 1.1412e-01, 8.1001e-03,
7.4638e-01, 6.9028e-01, 3.3555e-01, 1.2327e-01],
[6.1810e-05, 5.2777e-01, 9.7296e-01, 6.8016e-01, 9.2669e-01, 9.0223e-01,
6.3513e-01, 4.3459e-01, 1.5316e-02, 2.4932e-01]])
```
