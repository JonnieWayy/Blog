---
title: "[论文阅读笔记 -- 自监督学习] The Devil is in the Details for Vehicle ReID (ECCV 2020)"
date: 2021-12-29T15:05:23+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "self-supervised", "reid", "vehicle"]
draft: false
---

# The Devil is in the Details: Self-Supervised Attention for Vehicle Re-Identification (ECCV 2020)

![Fig 1](/images/2021/PRN149/1.png)

## 概述

本文提出一种针对车辆 ReID 的自监督注意力 (SAVER)，自动关注车辆图像中的显著区域而无需额外的人工标注。  

![Fig 2](/images/2021/PRN149/2.png)

## 自监督残差生成 (Self-Supervised Residual Generation)

旨在生成车辆的形状与结构而去除小尺度的信息，利用 VAE 架构实现，实验表明 AE 与 GAN 都倾向于引入额外扰动和细节，而 VAE 能得到更加平滑的纹理。  

利用 MSE 与 KL 散度对这一部分在大规模的 Vehicle Universe 数据集上进行预训练。  

不同于传统 VAE 的一点在于这里使用三维的潜在特征图，而非一维向量。  

得到粗略图像模板后与原图做差，得到残差图像。  

![Fig 3](/images/2021/PRN149/3.png)

## 深度特征提取

利用 ResNet-50 编码图像，损失函数用到三元组损失和交叉熵损失。  

## 可视化示例

![Fig 4](/images/2021/PRN149/4.png)

![Fig 5](/images/2021/PRN149/5.png)

![Fig 6](/images/2021/PRN149/6.png)

![Fig 7](/images/2021/PRN149/7.png)
