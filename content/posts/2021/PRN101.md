---
title: "[论文阅读笔记 -- 人机交互 / 跨模态检索] Interactive Natural Language Person Search (2020)"
date: 2021-09-24T19:53:50+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# 2002.08434v1 Interactive Natural Language-based Person Search (2020)

[CUHK-QA 数据集传送门](https://github.com/vikshree/QA_PersonSearchLanguageData)

![Fig 1](/images/2021/PRN101/1.png)

## 概述

可以认为本文是换了一种说法，把 Text-based Person Search 称为 Zero-shot re-ID。  

将 language-based re-ID 视为一种 VQA 任务，输入为图文对，输出为二值化答案。  

基于 VQA 算法 Pythia 进行修改提出 Pythia-reID 模型。  

在检索过程中，动态询问特定外观特征，定义了一个指导问题 (guiding questions) 集合。  

![Fig 2](/images/2021/PRN101/2.png)

## Pythia-reID

### 主要部件

#### 文本嵌入

预训练词嵌入 GloVe + GRU + 注意力模块  

#### 图像嵌入

ResNet-152 和 Faster-RCNN 提取 grid and region based features  

#### 空间注意力

基于图文特征的自上而下的注意力机制。  

#### 图文特征组合

结合注意力特征与文本特征得到最终的 VQA 特征。  

#### 分类器

给出匹配似然。  

### 训练策略

交叉熵损失。  

### 模型表现

![Tab 1](/images/2021/PRN101/T1.png)

### 检索结果示例

![Fig 3](/images/2021/PRN101/3.png)

## Supervised Information Retrieval for Person Search

采用序列化 QA 策略提升检索表现。  

### 贪心算法

![Alg 1](/images/2021/PRN101/A1.png)

### 数据集

构建了一个 CUHK-QA 数据集。  

![Tab 2](/images/2021/PRN101/T2.png)

![Fig 4](/images/2021/PRN101/4.png)

### 算法过程示例

![Fig 7](/images/2021/PRN101/7.png)

## Uncertainty Driven Information Retrieval

利用预测中的不确定性与文本描述中的信息内容决定是否需要附加信息来识别 POI。  

在图文检索任务中，图文相似度分数之间较为接近意味着网络对其预测结果有较高的不确定性，反之亦然。  

将相似度分数分布的熵作为衡量预测结果不确定性的指标。  

机器人持续发问，直到达到预设的熵级别，该级别称为不确定性预算 (budget of uncertainty)。  

$$E_{i} = - \sum_{j=1}^{n} \hat{a}\_{i, j} log(\hat{a}\_{i, j}).$$
