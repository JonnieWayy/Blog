---
title: "[论文阅读笔记 -- ReID] Weakly Supervised Text-Based Person Re-Identification (ICCV 2021)"
date: 2021-11-18T16:42:59+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Weakly Supervised Text-Based Person Re-Identification (ICCV 2021)

[开源代码传送门](https://github.com/X-BrainLab/WS_Text-ReID)

![Fig 1](/images/2021/PRN118/1.png)

## 概述

本文提出弱监督图文 ReID，即在训练阶段没有 ID 标注。  

### 新任务的两个困难
+ 各模态内由于类内差异造成的影响难以处理
+ 跨模态匹配模糊问题，对于一条文本描述，除了配对的图像以外无法给其他所有图像以正负标签

本文提出跨模态互训练架构 (Cross-Modal Mutual Training framework, CMMT)。  

![Fig 2](/images/2021/PRN118/2.png)

## Intra-Modal Self-Training by Pseudo Labels

### 出发点
由于训练集由图文对构成，在理想状况下，两个模态中的聚类结果应当一致，但类内差异会导致不一致。  

因而利用两模态之间的配对关系进一步优化聚类结果。  

![Fig 3](/images/2021/PRN118/3.png)

### Mutual Pseudo Label Refinement (MPLR)

进一步挖掘有价值的未聚类实例，而非直接丢弃，以进一步降低各模态内的类内差异。  

对于一个未聚类文本特征 \\(t_{i}^{o}\\)，可以通过配对实例搜索 (paired instance searching) 找到其配对的视觉实例 \\(v_{i}\\)：  

$$v_{i} = PIS(t_{i}^{o}).$$

如果得到的 \\(v_{i}\\) 也未聚类，则保持 \\(t_{i}^{o}\\) 未聚类，否则得到其近邻实例：  

$$v_{i}^c = arg max_{v_{i}^{c} \in C_{k}^{v}, v_{i}^{c} \notin U_{k}^{v}} <v_i, v_{i}^{c}>,$$

进而得到配对的文本实例：  

$$t_{i} = PIS(v_{i}^{c}),$$

如果 \\(t_{i} \in t^c\\)，则将未聚类特征加入到配对实例所在的聚类中：  

$$C_{k}^{t} \leftarrow [C_{k}^{t}, t_{i}^{o}].$$

## Text-IoU Guided Cross-Modal Projection Matching
