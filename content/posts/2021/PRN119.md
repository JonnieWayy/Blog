---
title: "[论文阅读笔记 -- ReID] Occluded ReID With Single-Scale Global Representation (ICCV 2021)"
date: 2021-11-20T17:40:34+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Occluded Person Re-Identification With Single-Scale Global Representations (ICCV 2021)

[数据集传送门（尚未更新）](https://github.com/daidaidouer/OP-ReID)

![Fig 1](/images/2021/PRN119/1.png)

## 概述

本文提出一种新的 ReID 模型，学习单尺度全局级别的行人表征 (single-scale global-level pedestrian representations)。  

构建了一个新的遮挡 ReID 数据集，称为 OPReID。  

![Fig 2](/images/2021/PRN119/2.png)

## Non-occuluded Feature Learning

### Occlusion-based Data Augmentation

采用复合批次删除增广的方法 (compound batch erasing augmentation method) 来模拟遮挡，包括两种方式：  
+ random erasing (RE)
+ batch-constant erasing (BcE)，将图像水平分割为 \\(s\\) 个部分，\\(s \in \\{6, 7, 8\\}\\) 是个随机值，进而随机选取并删除一块

得到两个增广后的 batch，拼成一个大的 batch 后作为模型的输入。  

### DNL-enabled Backbone and Reconstructive Pooling

采用 Disentangled Non-Local (DNL) 操作更好地提取非遮挡特征，通过计算所有位置上特征的加权和得到一个位置上的 neuron activation。  

在 ResNet-50 的第 2、第 3 阶段分别加上 2、3 个 DNL 层，DNL 的 pair-wise activation 计算如下：  

$$w(f_{i}, f_{j}) = softmax((W^q f_{i} - \mu_{q})^T (W^k f_{i} - \mu_{k})) + softmax(W^m f_{j}),$$

其中 \\(f_{i}\\) 是特征图在位置 \\(i\\) 上的 \\(c\\) 维特征，\\(W^q, W^k \in \mathbb{R}^{c \times c}\\)，\\(W^m \in \mathbb{R}^{1 \times c}\\)，两个 \\(\mu\\) 是相应 key 或 query 的均值。  

位置 \\(i\\) 的输出为 \\(\sum_{j} w(f_{i}, f_{j}) \cdot W^{v} f_{i}\\)，其中 \\(W^v \in \mathbb{R}^{c \times c}\\)。  

定义了一个新的重构池化操作 (reconstructive pooling) 并合入 backbone：  

$$f_{r} = (W^v F) softmax(W^m F)^T,$$

其中 \\(F \in \mathbb{R}^{c \times wh}\\) 是最终的特征图，前一项类似与金字塔匹配架构中的重构项，将完整图像特征重构为遮挡图像特征，后一项相当于通道上的特征选择层。该操作作用于 backbone 最后一个特征图以汇聚未遮挡特征，只在训练中使用，推断时直接用全局池化后的特征。

### Bounded Exponential Distance (BED) Loss

$$L_{bed}(x_{i}, x_{j}) = y_{ij}(1 - e^{-\alpha d(z_{i}, z_{j})}) + (1 - y_{ij}) e^{\alpha d(z_{i}, z_{j})},$$

其中 \\(z_{i} = \phi(x_{i})\\)，\\(d(\cdot, \cdot)\\) 是 \\(l_{2}\\) 距离。  

![Fig 3](/images/2021/PRN119/3.png)

### 完整的损失函数

$$L = L_{bed}^{rpf} + L_{bed}^{gf} + L_{c},$$
$$L_{c} = \\sum_{i}^{H} \mathbb{E}(\overline{Y}\_{i}, Y_{i}),$$

\\(L_{c}\\) 为基于交叉熵的多头分类损失，本文中取 \\(H = 2\\)。  

在真实场景 ReID 中通常存在长尾分布问题，本文采用 bad Momentum-effect Elimination (ME) 策略缓解该问题。  

SGD 优化过程中的动量会受到样本较多类别的主导，因而这里维护一个持续更新的均值特征向量，以捕捉动量转变：  

$$\mu_{t} = \beta \mu_{t - 1} + (1 - \beta) \cdot \widetilde{f}\_{g},$$

其中 \\(\widetilde{f}\_{g} = \frac{1}{B} \sum_{z \in \mathcal{B}} z\\)，在推断时减去最终的 \\(\mu\\) 从而消除偏差。  

## 数据集对比

![Tab 2](/images/2021/PRN119/T2.png)

![Fig 4](/images/2021/PRN119/4.png)

![Fig 5](/images/2021/PRN119/5.png)
