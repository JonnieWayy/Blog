---
title: "[论文阅读笔记 -- ReID] Syncretic Modality Collaborative Learning for VI-ReID (ICCV 2021)"
date: 2021-11-29T11:06:53+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Syncretic Modality Collaborative Learning for Visible Infrared Person Re-Identification (ICCV 2021)

![Fig 1](/images/2021/PRN129/1.png)

## 概述

### 现有借助第三模态方法的缺陷
+ 由可视图像生成，导致新模态和可视模态高度相关，但和红外模态不相关
+ 可视图像与红外图像的特征在学习到的嵌入空间中仍有很大的鸿沟

本文提出一种 syncretic modality collaborative learning (SMCL) 模型。  

![Fig 2](/images/2021/PRN129/2.png)

## Syncretic Modality Generative Module (SMGM)

首先是两个 \\(1 \times 1\\) 卷积层，接着进行像素对像素的特征融合：  

$$S_{n} = V_{n} \odot I_{n}, \ n \in \[1, N].$$

接着经过 ReLU 层与 \\(1 \times 1\\) 卷积层得到第三模态图像。  

## Challenge Enhanced Homogeneity Learning (CEHL)

用于将跨模态特征投影到一个一致空间中。  

对可视模态和第三模态正常计算 softmax 损失：  

$$\mathcal{L}\_{id}^{V} = -\frac{1}{N} \sum_{n=1}^{N} log \frac{e^{W_{yn}^{T} f_{n}^{V}}}{\sum_{u=1}^{U} e^{W_{u}^{T}f_{n}^{V}}}.$$

\\(\mathcal{L}\_{id}^{S}\\) 计算方式相同。而对于红外模态，提升对于分类器的难度：  

$$\mathcal{L}\_{id}^{I} = -\frac{1}{N} \sum_{n=1}^{N} log \frac{e^{W_{yn}^{T} f_{n}^{I} - m}}{\sum_{u=1}^{U} e^{W_{u}^{T}f_{n}^{I}}}.$$

## Auxiliary Distributional Similarity Learning (ADSL)

旨在增强跨模态类内相似度，并增大模态内类间差异。  

![Fig 3](/images/2021/PRN129/3.png)

## Incremental Training Strategy

![Alg 1](/images/2021/PRN129/A1.png)
