---
title: "[论文阅读笔记 -- ReID] Query-Adaptive Convolution and Temporal Lifting (ECCV 2020)"
date: 2021-11-08T12:14:22+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# Interpretable and Generalizable Person Re-Identification with Query-Adaptive Convolution and Temporal Lifting (ECCV 2020)

[开源代码传送门](https://github.com/ShengcaiLiao/QAConv)

![Fig 1-2](/images/2021/PRN111/1-2.png)

## 概述

现有的许多 ReID 方法只是在两个表征向量之间简单计算距离，而无视了两张图像真实内容之间的直接关系。  

本文考虑在深度特征映射过程中直接构建自适应于 query 的图像匹配，提出一种自适应于 query 的卷积方法 (Query-Adaptive Convolution, QAConv)，将图像匹配视为在特征图中找寻局部相关性，并构建自适应于 query 的卷积核以实现局部匹配。  

使得学习到的模型能够获益于最后一层的自适应卷积核，其特定于各张图像，此外匹配的过程与结果变得具有可解释性。  

构建一个类别记忆模块 (class memory module) 缓存各类别最近样本的特征图，以计算图像匹配损失，实现端到端训练。  

提出一种与模型无关的基于时序共现的分数权衡方法 (temporal cooccurrence based score weighting method)， 称为 Temporal Lifting (TLift)。  

![Fig 3-4](/images/2021/PRN111/3-4.png)

## QAConv

### QAConv 匹配

对 backbone 输出的 \\([1, d, h, w]\\) 的特征图的通道维用 l2 范数作正则化，进而提取各局部位置上尺度为 \\([s, s]\\) 的 local patch 重新组织为 \\([hw, d ,s, s]\\) 作为卷积核，输入通道数为 \\(d\\)，输出通道数为 \\(hw\\)。  

该卷积核的参数取决于输入，而非固定。可将自适应核作用于另一个特征图，得到 \\([1, hw, h, w]\\) 的相似度。  

由于通道维做了 l2 范数，当 \\(s = 1\\) 时相当于计算各局部之间的余弦相似度。又因为卷积核自适应地构建于图像内容，这些相似度的值恰好反映了两张输入图像之间的局部匹配结果。  

因而可以用全局最大值池化 (GMP) 选取出局部相关性最强的位置。  

### 网络架构

backbone CNN + QAConv layer + class memory layer + global max pooling layer + (d = 1) BN-FC-BN block + sigmoid function 

### 类别记忆与更新

维护一个 \\([c, d, h, w]\\) 的 tensor，\\(c\\) 表示类别数，在每个 batch 的训练过程中，采用直接赋值的更新策略 (direct assignment update strategy)。  

也可以采用 exponential moving average update 策略，但是这里表现不如直接赋值。  

### 损失函数

二元交叉熵损失。  

## Temporal Lifting

探究一个摄像头网络的先验时空结构 (prior spatial-temporal structure of a camera network)。  

### 基本假设

在一个摄像头下临近的行人在另一个摄像头下依然临近。  

## 结果示例

![Fig 1](/images/2021/PRN111/5.png)
