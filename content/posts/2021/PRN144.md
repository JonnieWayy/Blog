---
title: "[论文阅读笔记 -- 视觉对话] RAN with Reinforced Generator for Visual Dialog (TOMM 2020)"
date: 2021-12-27T17:59:41+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "visual dialog"]
draft: false
---

# Recurrent Attention Network with Reinforced Generator for Visual Dialog (TOMM 2020)

![Fig 1](/images/2021/PRN144/1.png)

## 概述

视觉对话 (Visual Dialog) 任务，代理 (agent) 根据所提供的图像与对话历史，回答关于图像中视觉内容的一系列具有时序关系的自然语言问题。  

### 两个主要问题
+ 如何使得代理有效解析时序上下文 (temporal context) 即对话历史，以准确理解当前问题
+ 如何根据问题及其时序上下文关注到图像中的特定区域

本文提出一种递归注意力网络 (Recurrent Attention Network)，以编码器-解码器架构尝试解决上述两个问题。  

![Fig 2](/images/2021/PRN144/2.png)

## 编码器
### 对话网络 (Dialog Network)

基于 LSTM，用于记忆对话历史，在各轮问答中以问题的嵌入向量作为输入，触发一个包含问题与对话历史信息的问题信号传给注意力处理器。  

在对话开始时，拼接图像特征和 caption 嵌入以初始化对话网络的状态。  

![Fig 3](/images/2021/PRN144/3.png)

### 注意力处理器 (Attention Processor)

结合注意力的 LSTM，用于解析视觉空间上下文，在问题信号指导下通过多次递归看图在图中定位问题需要的信息，最终生成一个状态向量 (state vector) 传给解码器。  

LSTM 记忆注意力历史并为回答问题收集视觉信息。  

其注意力机制如下：  
![Alg 1](/images/2021/PRN144/A1.png)

![Fig 4](/images/2021/PRN144/4.png)

## 解码器
### 生成模型 G

生成自然语言的回答，其优化时最大的问题在于缺少一个合适的损失函数，逐词匹配存在问题。  

### 鉴别模型 D

从候选中选出最佳回答，通过强化学习用于指导 G 的优化。  

## 注意力可视化示例

![Fig 5](/images/2021/PRN144/5.png)

## 结果示例

![Fig 6](/images/2021/PRN144/6.png)

![Fig 7](/images/2021/PRN144/7.png)
