---
title: "[论文阅读笔记 -- 知识蒸馏 / 互学习] Deep Mutual Learning (CVPR 2018)"
date: 2021-12-07T12:32:26+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "mutual learning", "knowledge distillation"]
draft: false
---

# Deep Mutual Learning (CVPR 2018)

[开源代码传送门 1](https://github.com/chxy95/Deep-Mutual-Learning)

[开源代码传送门 2](https://github.com/pilsHan/DML)

![Fig 1](/images/2021/PRN135/1.png)

## 概述

本文提出互学习 (mutual learning) 的概念，在若干个学生模型之间进行知识蒸馏。  

## 深度互学习

### 定义

由两个网络分别计算得到某个类的几率：  

$$p_{1}^{m}(x_{i}) = \frac{exp(z_{z}^m)}{\sum\_{m=1}^M exp(z_{1}^m)},$$
$$p_{2}^{m}(x_{i}) = \frac{exp(z_{z}^m)}{\sum\_{m=2}^M exp(z_{2}^m)},$$

各网络自身计算一个交叉熵损失，相互之间计算 KL 散度：  

$$D_{KL}(p_{2} || p_{1}) = \sum_{i=1}^N \sum_{m=1}^M p_{2}^m(x_{i}) log \frac{p_{2}^m (x_{i})}{p_{1}^m (x_{i})},$$
$$D_{KL}(p_{1} || p_{2}) = \sum_{i=1}^N \sum_{m=1}^M p_{1}^m(x_{i}) log \frac{p_{1}^m (x_{i})}{p_{2}^m (x_{i})},$$

由此两个模型的损失函数分别为：  

$$L_{\theta\_{1}} = L_{C\_{1}} + D_{KL}(p_{2} || p_{1}),$$
$$L_{\theta\_{2}} = L_{C\_{2}} + D_{KL}(p_{1} || p_{2}),$$

也可以用对称的 Jenson-Shannon Divergence Loss 替代不对称的 KL 散度：  

$$\frac{1}{2} (D_{KL}(p_{1} || p_{2}) + D_{KL}(p_{1} || p_{2})).$$

实验下来二者没有太大差异。  

### 优化过程

![Alg 1](/images/2021/PRN135/A1.png)

### 拓展到更多学生模型

$$L_{\theta\_{k}} = L_{C\_{k}} + \frac{1}{K - 1} \sum_{l=1, l \ne k}^K D_{KL}(p_{l} || p_{k}).$$  

### 拓展到半监督学习

在有标签的数据上计算交叉熵损失，而在所有训练数据上计算模仿损失，因为 KL 散度的计算并不需要类别标签。  
