---
title: "[论文阅读笔记 -- ViT] MetaFormer is Actually What You Need for Vision (2021)"
date: 2021-12-02T20:43:49+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "attention", "transformer", "ViT", "CNN"]
draft: false
---

# 2111.11418 MetaFormer is Actually What You Need for Vision (2021)

[开源代码传送门](https://github.com/sail-sg/poolformer)

![Fig 1](/images/2021/PRN133/1.png)

## 概述

Transformer 中的编码器包含两部分，其一是注意力模块，用于混合 token 之间的信息，本文称之为 token mixer；其二是其余的模块。  

本文将注意力模块视为一种特定的 token mixer，将整个 transformer 架构抽象为 MetaFormer。基于 MLP 甚至傅利叶变换的架构都可以视为 MetaFormer 的一种特殊实现，本文因而假设 transformer/MLP-like 系列模型的成功主要是由于 MetaFormer 架构。  

为了验证这一点，本文将 token mixer 实现为相对而言令牌混合能力较弱的池化操作，构建了 PoolFormer 架构，发现仍然能够得到较好的表现。  

## PoolFormer

![Fig 2](/images/2021/PRN133/2.png)

## 核心模块代码实现

![Alg 1](/images/2021/PRN133/A1.png)

![Alg 2](/images/2021/PRN133/A2.png)
