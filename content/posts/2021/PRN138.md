---
title: "[论文阅读笔记 -- ReID] PGGANet: Pose Guided Graph Attention Network for ReID (2021)"
date: 2021-12-20T17:26:20+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "cross-modal", "retrieval", "ReID"]
draft: false
---

# 2111.14411 PGGANet: Pose Guided Graph Attention Network for Person Re-identification (2021)

![Fig 1](/images/2021/PRN138/1.png)

## 概述

现有方法多只是将姿态热图与特征图相乘得到局部关键点特征，但这种做法并非最佳选择：  
+ backbone 输出的全局特征高度抽象，各个像素都与原图中很大一块区域对应，无用的背景部分很容易污染关键点像素的特征
+ 热图的稀疏性可能导致有用深度信息的丢失，且遮挡与不同的姿态视角可能引入负面影响
+ 现有方法直接拼接提取到的特征，没有考虑各局部特征的不同贡献，本文考虑用 GCN 为各局部特征生成独立的特征权重

本文提出一种姿态指导的图注意力网络 (Pose Guided Graph Attention Network, PGGAN)，包含三个分支学习不同粒度的特征。  

![Fig 2](/images/2021/PRN138/2.png)

![Fig 3](/images/2021/PRN138/3.png)

## Pose-Guided Attention Module (PGA)

网络分为全局、粗粒度和细粒度三个分支，将 ResNet-50 从 \\(res\\\_conv40\\) 分开，用其输出的 \\(H/8 \times W/8 \times 512\\) 特征图作为 PGA 模块的输入。姿态热图用同样的浅层 ResNet-50 得到。  

全局分支用完整的 ResNet-50 计算，结合 GMP 和 GAP，得到一个全局特征。  

粗粒度分支旨在让网络整体关注包含人体的粗糙区域。由于姿态热图是稀疏矩阵，直接相乘会导致特征稀疏化而损失细节信息，故此用各最大点的位置而非几率值来构建粗粒度注意力掩码。  

![Fig 4](/images/2021/PRN138/4.png)

由于姿态掩码只能提供空间维度的注意力区域，又引入一个通道注意力。得到一个全局特征和两个分别表示上下半身的局部特征。  

![Fig 5](/images/2021/PRN138/5.png)

![Fig 6](/images/2021/PRN138/6.png)

细粒度分支旨在使得网络关注 13 个预先定义的语义躯体部件对应的局部区域。直接相乘在存在遮挡或姿态变换时可能对网络产生误导，本文认为分别为各局部提取特征不合理，而应当指导网络自行学习该关注哪些部件。    

![Fig 7](/images/2021/PRN138/7.png)

沿着通道维将原始图像特征分组，与对应的掩码矩阵相乘。最终得到一个全局特征和三个局部特征。  

## Self-Adaptive Graph Attention Module (SAGA)

最终由 PGA 模块得到八个特征向量，用 SAGA 重新衡量各向量的重要性。  

由于来自不同分支，各特征并不在同一个特征空间里，直接用 GCN 得不到最佳表现，因而本文用 GCN 为各特征节点生成重要性权重系数。将三个全局向量的权重设为 1，将另外 5 个局部向量用作输入的节点特征，通过余弦相似度距离生成边，对邻接矩阵各行做 L2 规范化后得到 GCN 模块。  

![Fig 8](/images/2021/PRN138/8.png)

## 损失函数
ID loss + hard-triplet loss  

## 可视化示例
![Fig 9](/images/2021/PRN138/9.png)

![Fig 10](/images/2021/PRN138/10.png)
