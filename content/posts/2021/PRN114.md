---
title: "[论文阅读笔记 -- ViT] Escaping the Big Data Paradigm with Compact Transformers (2021)"
date: 2021-11-10T20:39:25+08:00
categories: ["Paper Reading Notes"]
tags: ["paper reading", "cv", "notes", "attention", "transformer", "ViT", "CNN"]
draft: false
---

# 2104.05704 Escaping the Big Data Paradigm with Compact Transformers (2021)

![Fig 1](/images/2021/PRN114/1.png)

## 概述

针对 Transformer 模型的数据饥饿 (data hungry) 传统观点，尝试弥合 Transformer 和 CNN 两种架构之间的鸿沟，结合二者优势，使得基于 Transformer 的模型能够在小型数据集上从头训练。  

本文首先提出 Vit-Lite，通过进一步增加序列池化，构建了 Compact Vision Transformer (CVT)，又通过在令牌化步骤中增加卷积块，构建了 Compact Convolutional Transformer (CCT)，后二者无需 [class] 令牌，增加了灵活性。  

![Fig 2](/images/2021/PRN114/2.png)

## 卷积块

用于取代 ViT 中的 image patching 层和嵌入层：  

$$x_{0} = MaxPool(ReLU(Conv2d(x))).$$  

CCT 不要求一张图像能被均分为 patch，且卷及和池化操作可以有重叠地进行。  

## SeqPool

旨在将序列化输出映射为单类别索引，而非需要使用类别令牌。  

可视为一个映射变换 \\(T: \mathbb{R}^{b \times n \times d} \rightarrow \mathbb{R}^{b \times d}\\)：  

$$x_{L} = f(x_{0} \in \mathbb{R}^{b \times n \times d}),$$
$$x'\_{L} = softmax(g(x_{L})^{T}) \in \mathbb{R}^{b \times 1 \times n},$$
$$z = x'\_{L}x_{L} = softmax(g(x_{L})^{T}) \times x_{L} \in \mathbb{R}^{b \times 1 \times d}.$$

## CCT vs. CVT

![Fig 3](/images/2021/PRN114/3.png)
